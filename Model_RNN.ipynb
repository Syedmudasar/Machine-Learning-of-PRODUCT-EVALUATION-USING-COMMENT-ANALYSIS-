{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qioFe3MYvCKE"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import gzip\n",
    "import nltk\n",
    "import pydot\n",
    "import shutil\n",
    "import string\n",
    "import sklearn\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "from google.colab import files\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# from keras.utils import to_categorical\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "khX7I9mVvbTf",
    "outputId": "e93afdcb-df96-4fc9-c098-1eaab01c665c"
   },
   "outputs": [],
   "source": [
    "!wget http://deepyeti.ucsd.edu/jianmo/amazon/categoryFiles/Electronics.json.gz     \n",
    "!wget http://deepyeti.ucsd.edu/jianmo/amazon/categoryFiles/AMAZON_FASHION.json.gz\n",
    "!wget http://deepyeti.ucsd.edu/jianmo/amazon/categoryFiles/Appliances.json.gz\n",
    "!wget http://deepyeti.ucsd.edu/jianmo/amazon/categoryFiles/Clothing_Shoes_and_Jewelry.json.gz\n",
    "!wget http://deepyeti.ucsd.edu/jianmo/amazon/categoryFiles/Home_and_Kitchen.json.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nu25xEypvc6z"
   },
   "outputs": [],
   "source": [
    "# Defining functions\n",
    "def clean_str(string):\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    return string.strip().lower()\n",
    "\n",
    "def chkList(lst):\n",
    "    return len(set(lst)) == 1\n",
    "\n",
    "def plot_graphs(history, string, plotname='plot.png'):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.plot(history.history['val_'+string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.legend([string, 'val_'+string])\n",
    "  plt.savefig(plotname)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lHeUTmjgvgzL"
   },
   "outputs": [],
   "source": [
    "# Defining some constants. \n",
    "learning_rate = 1e-3\n",
    "dropout = 0.4\n",
    "max_features =10000000\n",
    "embedding_dim =16\n",
    "sequence_length = 100\n",
    "batch_size =256\n",
    "epochs = 25\n",
    "each_category=1000\n",
    "word_count_threshold= 5\n",
    "BUFFER_SIZE = 800\n",
    "BATCH_SIZE = 256\n",
    "model_name= 'CommentAnalysis_RNN7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lWLTDPumvkLE",
    "outputId": "96a973f0-1981-4dc9-998b-c952e02f443e"
   },
   "outputs": [],
   "source": [
    "# Extracting data from data files\n",
    "comments=[]\n",
    "ratings=[]    \n",
    "data_files=os.listdir(os.getcwd())            \n",
    "for data in data_files:\n",
    "  if data[-2:] == 'gz':\n",
    "    print(\"Extracting data from file: \" + data)\n",
    "    data_from_each_category =[each_category,0,0,0,0,0]\n",
    "    with gzip.open(data) as f:\n",
    "        for l in f:\n",
    "            i=(json.loads(l.strip()))\n",
    "            if i.__contains__('overall') and  i.__contains__('reviewText'):\n",
    "                if(data_from_each_category[int(i['overall'])] < each_category):\n",
    "                    ratings.append(int(i['overall']))\n",
    "                    comments.append(' '.join(i['reviewText'].split()))\n",
    "                    data_from_each_category[int(i['overall'])] = data_from_each_category[int(i['overall'])]+1\n",
    "            if(chkList(data_from_each_category) and data_from_each_category[1] == each_category):\n",
    "                break\n",
    "        print('Data of each class from  data file '+ data + ':: ' +str(data_from_each_category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iOJMvk6J3NNY"
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "ratings=to_categorical(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BuHgXaWlld8P",
    "outputId": "0da15692-0dcd-4c1b-941d-5fae8cee461b"
   },
   "outputs": [],
   "source": [
    "# Downloading stopswords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "018fvGpJvm5H"
   },
   "outputs": [],
   "source": [
    "word_freq = {}\n",
    "for comment in comments:\n",
    "    comment = clean_str(comment)\n",
    "    words = comment.split()\n",
    "    for word in words:\n",
    "        if word in word_freq:\n",
    "            word_freq[word] += 1\n",
    "        else:\n",
    "            word_freq[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ndzGHC_Ovomi"
   },
   "outputs": [],
   "source": [
    "clean_comments = []\n",
    "for comment in comments:\n",
    "    comment = clean_str(comment)\n",
    "    words = comment.split()\n",
    "    doc_words = []\n",
    "    for word in words:\n",
    "        if word not in stop_words and word_freq[word] >= word_count_threshold:\n",
    "          doc_words.append(word)\n",
    "    doc_str = ' '.join(doc_words).strip()\n",
    "    clean_comments.append(doc_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gbWv4E--vryv",
    "outputId": "0f2893a0-2687-4342-8659-64c0a797064c"
   },
   "outputs": [],
   "source": [
    "print('Size of ratings list: '+str(len(ratings)))\n",
    "print('Size of comments list: '+str(len(clean_comments)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uO3LER2Uvud9",
    "outputId": "96aab81f-7fd9-449e-a50c-5362f9c29ef0"
   },
   "outputs": [],
   "source": [
    "# Tokenization of words\n",
    "num_words = len(word_freq)\n",
    "tokenizer = Tokenizer(num_words=num_words,oov_token=\"unk\")\n",
    "tokenizer.fit_on_texts(clean_comments)\n",
    "print('Example of tokenizer: '+ str(tokenizer.texts_to_sequences(['daughter thought good read'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xBbNtf-cvxvc"
   },
   "outputs": [],
   "source": [
    "\n",
    "#  Spliting data into test data and train data\n",
    "X_train, X_test, y_train, y_test = train_test_split(clean_comments,ratings,test_size=0.40,stratify = ratings,random_state=0)\n",
    "\n",
    "#  Spliting  test data into test data and validation data \n",
    "X_test, X_valid, y_test, y_valid = train_test_split(X_test,y_test,stratify = y_test,test_size=0.50,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oHaDTQtQv6Ab"
   },
   "outputs": [],
   "source": [
    "# Conversion from texts to sequences of train data and adding padding\n",
    "x_train = np.array(X_train)\n",
    "train_labels = np.asarray(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1f43FODpwQDI"
   },
   "outputs": [],
   "source": [
    "# Conversion from texts to sequences of validation data and adding padding\n",
    "x_valid = np.array(X_valid)\n",
    "valid_labels = np.asarray(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SZLSKongwX18"
   },
   "outputs": [],
   "source": [
    "# Conversion from texts to sequences of test data and adding padding\n",
    "x_test = np.array(X_test)\n",
    "test_labels = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6mVftYpEwfO7"
   },
   "outputs": [],
   "source": [
    "# Coversion of datas into tf.data.Dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train,train_labels))\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((x_valid,valid_labels))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-uGLMlirwhAe"
   },
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "valid_dataset = valid_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "un6QICFiwjPe",
    "outputId": "b18238d5-6637-4324-fc33-41ce29c6fd38"
   },
   "outputs": [],
   "source": [
    "for example, label in train_dataset.take(1):\n",
    "  print('texts: ', example.numpy()[:3])\n",
    "  print()\n",
    "  print('labels: ', label.numpy()[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_tqF-j59wl1S"
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE= len(word_freq)\n",
    "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(max_tokens=VOCAB_SIZE,output_sequence_length=140)\n",
    "encoder.adapt(train_dataset.map(lambda text, label: text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ti8Ua3-4w_7Z",
    "outputId": "2380c584-4810-4149-a898-984c4862d1e9"
   },
   "outputs": [],
   "source": [
    "vocab = np.array(encoder.get_vocabulary())\n",
    "vocab[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d50brAdTxCP1",
    "outputId": "32aca22c-d03a-4c8b-e5f1-00518c6a4a93"
   },
   "outputs": [],
   "source": [
    "encoded_example = encoder(example)[:3].numpy()\n",
    "encoded_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n9Z79r1YxE6t"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(len(encoder.get_vocabulary()), 150, mask_zero=True),\n",
    "  \ttf.keras.layers.Bidirectional(tf.keras.layers.LSTM(120,dropout=0.2, recurrent_dropout=0.2,return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100,dropout=0.2, recurrent_dropout=0.2)),\n",
    "    tf.keras.layers.Dense(84, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(6,activation='softmax',use_bias=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VnfggmPZxJw0"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer=tf.keras.optimizers.Adam(learning_rate),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PLX1e7BDxLHg",
    "outputId": "a27839de-59a1-404d-c5de-47f025a839a8"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset, epochs=epochs,validation_data=test_dataset,validation_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HUH5gRlwIn_Q",
    "outputId": "64459d3c-5853-440d-f8d2-c8c9d10e4916"
   },
   "outputs": [],
   "source": [
    "test_results = model.evaluate(test_dataset, batch_size=128)\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2T2llLSO24jr",
    "outputId": "e89e490f-f6d4-40c0-c06c-e49edd9a9ba8"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ng-JEIKNxNux",
    "outputId": "ebe0d4a6-f40b-4687-ad6f-f51fa17bcd70"
   },
   "outputs": [],
   "source": [
    "history.history                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mN3XK7TqygVw",
    "outputId": "419bb4dc-4594-4f22-9132-4de828b734cd"
   },
   "outputs": [],
   "source": [
    "plot_graphs(history, \"accuracy\",\"accuracy.jpg\")\n",
    "plot_graphs(history, \"loss\",\"loss.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "mCAnRY4TQ4pL"
   },
   "outputs": [],
   "source": [
    "pred_test_label = []\n",
    "labels = [0,1,2,3,4,5]\n",
    "test_pred = model.predict(test_dataset)\n",
    "for i in test_pred:\n",
    "  pred_test_label.append(np.argmax(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "KBOh3-CNqyyc",
    "outputId": "d97b093c-f1fd-4f7c-b021-a8a3ee2c764a"
   },
   "outputs": [],
   "source": [
    "# Saving model for future use \n",
    "model.save(model_name+'.tf') "
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Model_RNN",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
